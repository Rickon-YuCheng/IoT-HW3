from __future__ import annotations

import json
from pathlib import Path
from typing import Any, Dict

import joblib
import pandas as pd
import streamlit as st

from src.data_utils import RAW_DATA_PATH, load_dataset


ARTIFACT_DIR = Path("artifacts")
REPORTS_PATH = Path("reports/metrics.json")
MODEL_LABELS = {
    "linear_svm": "ç·šæ€§ SVM",
    "logistic_regression": "é‚è¼¯æ–¯è¿´æ­¸",
}
CTA_MESSAGE = "å³åˆ»é«”é©—æ¨¡å‹ã€æ¯”è¼ƒæŒ‡æ¨™ä¸¦æª¢è¦–è³‡æ–™æ´å¯Ÿã€‚"
SAMPLE_MESSAGES = {
    "æŠ½çè©é¨™": "Congratulations! You've won a free ticket. Call now to claim.",
    "å¸³å–®é€šçŸ¥": "Reminder: Your invoice will be charged tomorrow unless you cancel.",
    "æƒ¡æ„é€£çµ": "Claim urgent refund at http://scam.link within 1 hour to avoid penalty.",
    "æ—¥å¸¸èŠå¤©": "Hey, are we still meeting for coffee this afternoon?",
}


@st.cache_resource
def load_pipeline(model_key: str):
    path = ARTIFACT_DIR / f"{model_key}_pipeline.joblib"
    if not path.exists():
        raise FileNotFoundError(
            f"æ‰¾ä¸åˆ°æ¨¡å‹æª”æ¡ˆ {path}ï¼Œè«‹å…ˆåŸ·è¡Œ `python -m src.train` ç”¢ç”Ÿæ¨¡å‹ã€‚"
        )
    return joblib.load(path)


@st.cache_data
def load_metrics() -> Dict[str, Any]:
    if not REPORTS_PATH.exists():
        raise FileNotFoundError(
            f"æ‰¾ä¸åˆ°å ±å‘Šæª”æ¡ˆ {REPORTS_PATH}ï¼Œè«‹å…ˆåŸ·è¡Œ `python -m src.train` ç”¢ç”Ÿå ±è¡¨ã€‚"
        )
    return json.loads(REPORTS_PATH.read_text(encoding="utf-8"))


@st.cache_data
def load_sample_data(limit: int = 5) -> pd.DataFrame:
    if not RAW_DATA_PATH.exists():
        return pd.DataFrame(columns=["label", "message"])
    df = load_dataset()
    df["label"] = df["label"].map({1: "spam", 0: "ham"})
    return df.sample(n=min(limit, len(df)), random_state=42)


@st.cache_data
def load_dataset_overview() -> Dict[str, Any]:
    if not RAW_DATA_PATH.exists():
        return {}
    df = load_dataset()
    label_counts = df["label"].value_counts().rename({1: "spam", 0: "ham"})
    avg_length = df["message"].str.len().mean()
    return {
        "count": len(df),
        "label_counts": label_counts.to_dict(),
        "avg_length": avg_length,
    }


def render_hero(metadata: Dict[str, Any]) -> None:
    st.markdown(
        """
        <div style="
            background: linear-gradient(120deg,#2b5876,#4e4376);
            padding: 2.5rem 2.75rem;
            border-radius: 20px;
            color: #ffffff;
        ">
            <h1 style="margin-bottom: 0.5rem;">ğŸ“¬ åƒåœ¾éƒµä»¶åˆ†é¡æ§åˆ¶å°</h1>
            <p style="font-size: 1.05rem; margin-bottom: 0.75rem;">
                ä½¿ç”¨ TF-IDF ç‰¹å¾µå·¥ç¨‹èˆ‡é›™æ¨¡å‹æ¯”è¼ƒï¼ˆç·šæ€§ SVMã€é‚è¼¯æ–¯è¿´æ­¸ï¼‰ï¼Œå¿«é€Ÿè¾¨è­˜åƒåœ¾ç°¡è¨Šã€‚
            </p>
            <div style="display: flex; gap: 1.5rem; flex-wrap: wrap;">
                <div>
                    <span style="font-size: 0.9rem; opacity: 0.8;">è¨“ç·´æ¨£æœ¬æ•¸</span>
                    <h3 style="margin: 0;">{train}</h3>
                </div>
                <div>
                    <span style="font-size: 0.9rem; opacity: 0.8;">é©—è­‰æ¨£æœ¬æ•¸</span>
                    <h3 style="margin: 0;">{test}</h3>
                </div>
                <div>
                    <span style="font-size: 0.9rem; opacity: 0.8;">å¿«é€Ÿå°è¦½</span>
                    <h3 style="margin: 0;">{cta}</h3>
                </div>
            </div>
        </div>
        """.format(
            train=metadata.get("train_size", "N/A"),
            test=metadata.get("test_size", "N/A"),
            cta=CTA_MESSAGE,
        ),
        unsafe_allow_html=True,
    )


def render_prediction_tab(model_key: str, metrics: Dict[str, Any]) -> None:
    pipeline = load_pipeline(model_key)
    classifier = pipeline.named_steps["classifier"]
    vectorizer = pipeline.named_steps["vectorizer"]

    st.subheader("é«”é©—å³æ™‚åˆ†é¡")
    st.caption("è¼¸å…¥éƒµä»¶å…§å®¹æˆ–å¥—ç”¨å¸¸è¦‹ç¯„ä¾‹ï¼Œæ¨¡å‹æœƒå³æ™‚å›å ±çµæœèˆ‡ä¿¡å¿ƒåˆ†æ•¸ã€‚")

    col_msg, col_result = st.columns([2, 1])
    with col_msg:
        with st.expander("æ’å…¥ç¯„ä¾‹è¨Šæ¯", expanded=False):
            sample_choice = st.radio(
                "é¸æ“‡ç¯„ä¾‹ï¼ˆå¯è‡ªè¡Œç·¨è¼¯å¾Œå†é€å‡ºï¼‰",
                options=list(SAMPLE_MESSAGES.values()),
                format_func=lambda text: next(
                    label for label, content in SAMPLE_MESSAGES.items() if content == text
                ),
                index=0,
            )
        user_input = st.text_area(
            "éƒµä»¶å…§å®¹",
            sample_choice,
            height=180,
        )

    with col_result:
        st.markdown("#### æ¨¡å‹é¸æ“‡")
        st.markdown(f"**{MODEL_LABELS[model_key]}**")
        st.markdown("---")
        run_prediction = st.button("ğŸš€ åŸ·è¡Œåˆ†é¡", type="primary")

        if run_prediction:
            features = vectorizer.transform([user_input])
            prediction = classifier.predict(features)[0]
            label = "ğŸ“› Spam" if prediction == 1 else "âœ… Ham"
            st.markdown(f"### {label}")

            if hasattr(classifier, "predict_proba"):
                proba = classifier.predict_proba(features)[0]
                st.metric("Spam æ©Ÿç‡", f"{proba[1]:.2%}", delta=None)
                st.metric("Ham æ©Ÿç‡", f"{proba[0]:.2%}", delta=None)
            elif hasattr(classifier, "decision_function"):
                score = classifier.decision_function(features)[0]
                st.metric("Decision Function åˆ†æ•¸", f"{score:.4f}")
            else:
                st.info("æ­¤æ¨¡å‹ç„¡æ©Ÿç‡è¼¸å‡ºï¼Œåƒ…ä¾›äºŒå…ƒåˆ†é¡åˆ¤æ–·ã€‚")
        else:
            st.info("æŒ‰ä¸‹ã€ŒğŸš€ åŸ·è¡Œåˆ†é¡ã€å³å¯æŸ¥çœ‹çµæœã€‚")


def render_metrics_tab(metrics: Dict[str, Any]) -> None:
    st.subheader("æ¨¡å‹è¡¨ç¾ç¸½è¦½")
    metric_rows = []
    for key, payload in metrics.items():
        if key == "metadata":
            continue
        metric_rows.append(
            {
                "æ¨¡å‹": MODEL_LABELS.get(key, key),
                "Accuracy": payload["accuracy"],
                "Precision": payload["precision"],
                "Recall": payload["recall"],
                "F1": payload["f1"],
            }
        )

    metric_df = pd.DataFrame(metric_rows).set_index("æ¨¡å‹")

    col_cards = st.columns(len(metric_df))
    for col, (model_name, row) in zip(col_cards, metric_df.iterrows()):
        with col:
            st.metric("æ¨¡å‹", model_name)
            st.metric("Accuracy", f"{row['Accuracy']:.3f}")
            st.metric("F1", f"{row['F1']:.3f}")
            st.caption(f"Precision: {row['Precision']:.3f} Â· Recall: {row['Recall']:.3f}")

    st.markdown("### æŒ‡æ¨™è¶¨å‹¢æ¯”è¼ƒ")
    st.dataframe(metric_df.style.format("{:.3f}"), use_container_width=True)

    st.markdown("### è©³ç´°åˆ†é¡å ±å‘Š")
    tabs = st.tabs(list(metric_df.index))
    for tab, key in zip(tabs, [k for k in metrics.keys() if k != "metadata"]):
        with tab:
            st.code(metrics[key]["classification_report"], language="text")


def render_dataset_tab() -> None:
    st.subheader("è³‡æ–™æ¢ç´¢")
    overview = load_dataset_overview()
    if not overview:
        st.info("å°šæœªä¸‹è¼‰è³‡æ–™é›†ï¼Œè«‹å…ˆåŸ·è¡Œè¨“ç·´è…³æœ¬ã€‚")
        return

    col1, col2, col3 = st.columns(3)
    col1.metric("æ¨£æœ¬ç¸½æ•¸", f"{overview['count']}")
    spam_count = overview["label_counts"].get("spam", 0)
    ham_count = overview["label_counts"].get("ham", 0)
    col2.metric("Spam / Ham", f"{spam_count} / {ham_count}")
    col3.metric("å¹³å‡è¨Šæ¯é•·åº¦", f"{overview['avg_length']:.1f} å­—å…ƒ")

    st.markdown("### éš¨æ©Ÿæ¨£æœ¬")
    st.caption("ä¿è­·å€‹è³‡ï¼šè³‡æ–™ä¾†æºç‚ºå…¬é–‹ SMS åƒåœ¾è¨Šæ¯è³‡æ–™é›†ã€‚")
    sample_df = load_sample_data(limit=10)
    st.table(sample_df)


def render_project_tab() -> None:
    st.subheader("å°ˆæ¡ˆä½¿ç”¨æŒ‡å—")
    st.markdown(
        """
        - âœ… **æº–å‚™ç’°å¢ƒ**ï¼š`python3 -m venv .venv && source .venv/bin/activate && pip install -r requirements.txt`
        - ğŸ› ï¸ **é‡æ–°è¨“ç·´æ¨¡å‹**ï¼š`python -m src.train`ï¼ˆå«è³‡æ–™ä¸‹è¼‰èˆ‡å ±è¡¨ç”¢ç”Ÿï¼‰
        - ğŸŒ **å•Ÿå‹•ä»‹é¢**ï¼š`streamlit run streamlit_app.py`
        - ğŸš€ **éƒ¨ç½²å»ºè­°**ï¼šä½¿ç”¨ Streamlit Community Cloudï¼Œä¸¦è¨˜å¾—å°‡éƒ¨ç½²ç¶²å€è£œå› READMEã€‚
        - ğŸ“¦ **å°ˆæ¡ˆçµæ§‹**ï¼š`src/` ç‚ºè³‡æ–™èˆ‡æ¨¡å‹æµç¨‹ã€`reports/` å­˜æ”¾æŒ‡æ¨™ã€`artifacts/` å„²å­˜æ¨¡å‹ã€‚
        """
    )
    st.info("æç¤ºï¼šè‹¥é¦–æ¬¡å•Ÿå‹•ï¼Œè«‹å…ˆåŸ·è¡Œè¨“ç·´è…³æœ¬ä»¥ç”¢ç”Ÿæ¨¡å‹èˆ‡å ±å‘Šã€‚")


def main() -> None:
    st.set_page_config(page_title="åƒåœ¾éƒµä»¶åˆ†é¡æ§åˆ¶å°", page_icon="ğŸ“¬", layout="wide")

    metrics = load_metrics()
    metadata = metrics.get("metadata", {})
    render_hero(metadata)

    model_key = st.selectbox(
        "æƒ³è¦æ¯”è¼ƒçš„æ¨¡å‹",
        options=list(MODEL_LABELS.keys()),
        format_func=lambda key: MODEL_LABELS.get(key, key),
        index=0,
        help="å¯åˆ‡æ›ä¸åŒæ¨¡å‹ä»¥æŸ¥çœ‹æŒ‡æ¨™èˆ‡é æ¸¬çµæœã€‚",
    )

    tab_predict, tab_metrics, tab_dataset, tab_project = st.tabs(
        ["å³æ™‚é æ¸¬", "æ¨¡å‹æ´å¯Ÿ", "è³‡æ–™æ¢ç´¢", "å°ˆæ¡ˆæŒ‡å—"]
    )

    with tab_predict:
        render_prediction_tab(model_key, metrics)

    with tab_metrics:
        render_metrics_tab(metrics)

    with tab_dataset:
        render_dataset_tab()

    with tab_project:
        render_project_tab()

    st.markdown("---")
    st.caption(
        "è³‡æ–™ä¾†æºï¼šHands-On Artificial Intelligence for Cybersecurity - SMS Spam Dataset."
    )


if __name__ == "__main__":
    main()
